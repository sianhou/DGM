{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T04:30:54.104969300Z",
     "start_time": "2026-01-06T04:30:50.258503400Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.datasets import make_moons\n",
    "from torch import nn, Tensor"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T04:30:56.508977100Z",
     "start_time": "2026-01-06T04:30:56.435280400Z"
    }
   },
   "source": [
    "class Flow(nn.Module):\n",
    "    def __init__(self, dim: int = 2, h: int = 64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim + 1, h), nn.ELU(),\n",
    "            nn.Linear(h, h), nn.ELU(),\n",
    "            nn.Linear(h, h), nn.ELU(),\n",
    "            nn.Linear(h, dim))\n",
    "\n",
    "    def forward(self, t: Tensor, x_t: Tensor) -> Tensor:\n",
    "        return self.net(torch.cat((t, x_t), -1))\n",
    "\n",
    "    def step(self, x_t: Tensor, t_start: Tensor, t_end: Tensor) -> Tensor:\n",
    "        t_start = t_start.view(1, 1).expand(x_t.shape[0], 1)\n",
    "\n",
    "        return x_t + (t_end - t_start) * self(t=t_start + (t_end - t_start) / 2,\n",
    "                                              x_t=x_t + self(x_t=x_t, t=t_start) * (t_end - t_start) / 2)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T06:33:22.598077600Z",
     "start_time": "2026-01-06T06:32:23.341094700Z"
    }
   },
   "source": [
    "flow = Flow()\n",
    "\n",
    "optimizer = torch.optim.Adam(flow.parameters(), 1e-2)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(10000):\n",
    "    x_1 = Tensor(make_moons(256, noise=0.15)[0])\n",
    "    x_0 = torch.randn_like(x_1)\n",
    "    t = torch.rand(len(x_1), 1)\n",
    "\n",
    "    x_t = (1 - t) * x_0 + t * x_1\n",
    "    dx_t = x_1 - x_0\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_fn(flow(t=t, x_t=x_t), dx_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"epoch: {epoch}, loss: {loss.item():.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 2.0352\n",
      "epoch: 1000, loss: 1.1233\n",
      "epoch: 2000, loss: 0.9559\n",
      "epoch: 3000, loss: 1.0625\n",
      "epoch: 4000, loss: 0.9148\n",
      "epoch: 5000, loss: 0.9814\n",
      "epoch: 6000, loss: 1.1472\n",
      "epoch: 7000, loss: 1.0905\n",
      "epoch: 8000, loss: 1.0585\n",
      "epoch: 9000, loss: 1.0756\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "x = torch.randn(300, 2)\n",
    "n_steps = 8\n",
    "fig, axes = plt.subplots(1, n_steps + 1, figsize=(30, 4), sharex=True, sharey=True)\n",
    "time_steps = torch.linspace(0, 1.0, n_steps + 1)\n",
    "\n",
    "axes[0].scatter(x.detach()[:, 0], x.detach()[:, 1], s=10)\n",
    "axes[0].set_title(f't = {time_steps[0]:.2f}')\n",
    "axes[0].set_xlim(-3.0, 3.0)\n",
    "axes[0].set_ylim(-3.0, 3.0)\n",
    "\n",
    "for i in range(n_steps):\n",
    "    x = flow.step(x_t=x, t_start=time_steps[i], t_end=time_steps[i + 1])\n",
    "    axes[i + 1].scatter(x.detach()[:, 0], x.detach()[:, 1], s=10)\n",
    "    axes[i + 1].set_title(f't = {time_steps[i + 1]:.2f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Flow Matching\n",
    "We now train a simple conditional model using class labels."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class Flow(nn.Module):\n",
    "    def __init__(self, dim: int = 2, h: int = 64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim + 2, h), nn.ELU(),\n",
    "            nn.Linear(h, h), nn.ELU(),\n",
    "            nn.Linear(h, h), nn.ELU(),\n",
    "            nn.Linear(h, dim))\n",
    "\n",
    "    def forward(self, t: Tensor, c: Tensor, x_t: Tensor) -> Tensor:\n",
    "        return self.net(torch.cat((t, c, x_t), -1))\n",
    "\n",
    "    def step(self, x_t: Tensor, t_start: Tensor, t_end: Tensor, c: Tensor) -> Tensor:\n",
    "        t_start = t_start.view(1, 1).expand(x_t.shape[0], 1)\n",
    "\n",
    "        return x_t + (t_end - t_start) * self(t=t_start + (t_end - t_start) / 2, c=c,\n",
    "                                              x_t=x_t + self(c=c, x_t=x_t, t=t_start) * (t_end - t_start) / 2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "flow = Flow()\n",
    "\n",
    "optimizer = torch.optim.Adam(flow.parameters(), 1e-2)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for _ in range(10000):\n",
    "    x_1, c = make_moons(256, noise=0.15)\n",
    "    x_1 = Tensor(x_1)\n",
    "    c = Tensor(c)\n",
    "    c = c.view(-1, 1)\n",
    "\n",
    "    x_0 = torch.randn_like(x_1)\n",
    "    t = torch.rand(len(x_1), 1)\n",
    "\n",
    "    x_t = (1 - t) * x_0 + t * x_1\n",
    "    dx_t = x_1 - x_0\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss_fn(flow(t=t, x_t=x_t, c=c), dx_t).backward()\n",
    "    optimizer.step()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- evaluation / visualisation section --------------------------\n",
    "n_samples = 256\n",
    "\n",
    "sigma = 1.0\n",
    "x = torch.randn(n_samples, 2) * sigma  # (n_samples, 2)\n",
    "\n",
    "# if you just want random labels –– otherwise load real labels here\n",
    "c_eval = torch.randint(0, 2, (n_samples, 1), dtype=torch.float32)  # (n_samples, 1)\n",
    "\n",
    "# colours for the scatter (same length as x)\n",
    "colors = ['blue' if lbl == 0 else 'orange' for lbl in c_eval.squeeze().tolist()]\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "n_steps = 100\n",
    "plot_every = 20\n",
    "plot_indices = list(range(0, n_steps + 1, plot_every))\n",
    "if plot_indices[-1] != n_steps:\n",
    "    plot_indices.append(n_steps)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(plot_indices), figsize=(4 * len(plot_indices), 4),\n",
    "                         sharex=True, sharey=True)\n",
    "time_steps = torch.linspace(0, 1.0, n_steps + 1)\n",
    "\n",
    "# initial frame\n",
    "axes[0].scatter(x[:, 0], x[:, 1], s=10, c=colors)\n",
    "axes[0].set_title(f't = {time_steps[0]:.2f}')\n",
    "axes[0].set_xlim(-3.0, 3.0)\n",
    "axes[0].set_ylim(-3.0, 3.0)\n",
    "\n",
    "plot_count = 0\n",
    "with torch.no_grad():  # no gradients while sampling\n",
    "    for i in range(n_steps):\n",
    "        x = flow.step(x_t=x,\n",
    "                      t_start=time_steps[i],\n",
    "                      t_end=time_steps[i + 1],\n",
    "                      c=c_eval)  # 2️⃣ use the same‑sized label tensor\n",
    "        if (i + 1) in plot_indices:\n",
    "            plot_count += 1\n",
    "            axes[plot_count].scatter(x[:, 0], x[:, 1], s=10, c=colors)\n",
    "            axes[plot_count].set_title(f't = {time_steps[i + 1]:.2f}')\n",
    "            axes[plot_count].set_xlim(-3.0, 3.0)\n",
    "            axes[plot_count].set_ylim(-3.0, 3.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DiT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
